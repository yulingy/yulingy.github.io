<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yuling Yan</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yuling Yan</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="experience.html">Experiences</a></div>
<div class="menu-item"><a href="research.html">Papers</a></div>
<div class="menu-item"><a href="CV_Yuling_Yan.pdf">CV</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="STAT615_Fall24.html">STAT&nbsp;615</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Yuling Yan</h1>
</div>
<table class="imgtable"><tr><td>
<img src="Photo/yuling_yan.jpeg" alt="alt text" width="240px" height="240px" />&nbsp;</td>
<td align="left"><p>Starting Aug 2024, I am an assistant professor in the <a href="https://stat.wisc.edu">Department of Statistics</a> at University of Wisconsin-Madison.</p>
<p>Previously, I spent one year as a Norbert Wiener Postdoctoral Associate at MIT, working with Professor <a href="https://math.mit.edu/~rigollet/">Philippe Rigollet</a> and Professor <a href="https://wainwrigwork.github.io/">Martin Wainwright</a>. I obtained my Ph.D. degree at Princeton University in 2023, advised by Professor <a href="https://yuxinchen2020.github.io/index.html">Yuxin Chen</a> and Professor <a href="https://orfe.princeton.edu/~jqfan/">Jianqing Fan</a>. I received my bachelor's degree from Peking University in 2018.<br /></p>
<p><b>Research interests</b>: statistics, mathematics of data science, and their applications to generative AI and social sciences. <br /></p>
<p><b>Contact</b>: <br />
7277 Medical Science Center <br />
1300 University Ave, Madison, WI 53706 <br /></p>
<p><b>E-mail</b>: <i>yuling.yan</i> [@] wisc [DOT] edu</p>
</td></tr></table>
<h2>Featured projects</h2>
<p>(*=equal contribution, <img class="eq" src="eqs/7227645438722938594-130.png" alt="alpha" style="vertical-align: -1px" />-<img class="eq" src="eqs/4226120147019918905-130.png" alt="beta" style="vertical-align: -4px" />=alphabetical order)</p>
<ul>
<li><p><b>Causal inference under staggered adoption</b> </p>
<ul>
<li><p><u>Y. Yan</u>, M.&nbsp;J.&nbsp;Wainwright, <a href="https://arxiv.org/abs/2401.13665">&ldquo;Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal Approach,&rdquo;</a> 2024 </p>
</li>
<li><p>E.&nbsp;Xia*, <u>Y. Yan</u>*, M.&nbsp;J.&nbsp;Wainwright, <a href="papers/causal_panel_obamacare.pdf">&ldquo;Inference under Staggered Adoption: Case Study of the Affordable Care Act,&rdquo;</a> 2024</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<img src="figures/staggered.png" alt="ACA illustration" width="880 px" height="IMGLINKTARGET" />&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><b>Learning in the space of probability measures (with applications to generative AI and nonparametric statistics)</b></p>
<ul>
<li><p><u>Y. Yan</u>*, K.&nbsp;Wang*, P.&nbsp;Rigollet, <a href="https://arxiv.org/abs/2301.01766">&ldquo;Learning Gaussian Mixtures Using the Wasserstein-Fisher-Rao Gradient Flow,&rdquo;</a> <i>Annals of Statistics, vol. 52, no. 4, pp. 1774-1795, 2024</i> </p>
</li>
<li><p>G.&nbsp;Li*, <u>Y. Yan</u>*, <a href="https://arxiv.org/abs/2405.14861">&ldquo;Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models,&rdquo;</a> <i>NeurIPS 2024</i></p>
</li>
<li><p>G.&nbsp;Li*, <u>Y. Yan</u>*, <a href="https://arxiv.org/abs/2408.16765">&ldquo;A Score-Based Density Formula, with Applications in Diffusion Generative Models,&rdquo;</a> 2024</p>
</li>
<li><p>G.&nbsp;Li*, <u>Y. Yan</u>*, <a href="https://arxiv.org/abs/2409.18959">&ldquo;O(d/T) Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions,&rdquo;</a> 2024</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<img src="figures/diffusion.png" alt="Diffusion model" width="900 px" height="IMGLINKTARGET" />&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><b>Mechanism design for improving peer review</b></p>
<ul>
<li><p><u>Y. Yan</u>, W.&nbsp;J.&nbsp;Su, J.&nbsp;Fan, <a href="papers/isotonic.pdf">&ldquo;Isotonic Mechanism for Exponential Family Estimation in Machine Learning Peer Review,&rdquo;</a> under major revision at <i>Journal of the Royal Statistical Society: Series B (discussion paper track)</i>, 2024</p>
</li>
<li><p>B.&nbsp;Su, J.&nbsp;Zhang, N.&nbsp;Collina, <u>Y. Yan</u>, D.&nbsp;Li, K.&nbsp;Cho, J.&nbsp;Fan, A.&nbsp;Roth, W.&nbsp;J.&nbsp;Su <a href="https://arxiv.org/abs/2408.13430">&ldquo;Analysis of the ICML 2023 Ranking Data: Can Authors&rsquo; Opinions of Their Own Papers Assist Peer Review in Machine Learning?&rdquo;</a> 2024</p>
</li>
</ul>

</li>
</ul>
<table class="imgtable"><tr><td>
<img src="figures/isotonic.png" alt="Diffusion model" width="920 px" height="IMGLINKTARGET" />&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p><b>Inference and uncertainty quantification for low-rank models</b></p>
<ul>
<li><p>Y.&nbsp;Chen, J.&nbsp;Fan, C.&nbsp;Ma, <u>Y. Yan</u> (<img class="eq" src="eqs/7227645438722938594-130.png" alt="alpha" style="vertical-align: -1px" />-<img class="eq" src="eqs/4226120147019918905-130.png" alt="beta" style="vertical-align: -4px" />), <a href="https://www.pnas.org/content/pnas/116/46/22931.full.pdf">&ldquo;Inference and Uncertainty Quantification for Noisy Matrix Completion,&rdquo;</a> <i>Proceedings of the National Academy of Sciences, vol. 116, no. 46, pp. 22931-22937, 2019</i></p>
</li>
<li><p><u>Y. Yan</u>, Y.&nbsp;Chen, J.&nbsp;Fan, <a href="https://projecteuclid.org/journals/annals-of-statistics/volume-52/issue-2/Inference-for-heteroskedastic-PCA-with-missing-data/10.1214/24-AOS2366.full">&ldquo;Inference for Heteroskedastic PCA with Missing Data,&rdquo;</a> <i>Annals of Statistics, vol. 52, no. 2, pp. 729â€“756, 2024</i></p>
</li>
<li><p>J.&nbsp;Fan, <u>Y. Yan</u>, Y.&nbsp;Zheng (<img class="eq" src="eqs/7227645438722938594-130.png" alt="alpha" style="vertical-align: -1px" />-<img class="eq" src="eqs/4226120147019918905-130.png" alt="beta" style="vertical-align: -4px" />) <a href="https://arxiv.org/abs/2407.03616">&ldquo;When Can Weak Latent Factors Be Statistically Inferred?&rdquo;</a> 2024</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b>Bridging convex and nonconvex optimization in low-rank estimation</b></p>
<ul>
<li><p>Y.&nbsp;Chen, C.&nbsp;Chi, J.&nbsp;Fan, C.&nbsp;Ma, <u>Y. Yan</u> (<img class="eq" src="eqs/7227645438722938594-130.png" alt="alpha" style="vertical-align: -1px" />-<img class="eq" src="eqs/4226120147019918905-130.png" alt="beta" style="vertical-align: -4px" />), <a href="https://epubs.siam.org/doi/pdf/10.1137/19M1290000">&ldquo;Noisy Matrix Completion: Understanding Statistical Guarantees for Convex Relaxation via Nonconvex Optimization,&rdquo;</a> <i>SIAM Journal on Optimization, vol. 30, no. 4, pp. 3098-3121, 2020</i></p>
</li>
<li><p>Y.&nbsp;Chen, J.&nbsp;Fan, C.&nbsp;Ma, <u>Y. Yan</u> (<img class="eq" src="eqs/7227645438722938594-130.png" alt="alpha" style="vertical-align: -1px" />-<img class="eq" src="eqs/4226120147019918905-130.png" alt="beta" style="vertical-align: -4px" />), <a href="https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-5/Bridging-convex-and-nonconvex-optimization-in-robust-PCA--Noise/10.1214/21-AOS2066.full">&ldquo;Bridging Convex and Nonconvex Optimization in Robust PCA: Noise, Outliers, and Missing Data,&rdquo;</a> <i>Annals of Statistics, vol. 49, no. 5, pp. 2948-2971, 2021</i></p>
</li>
<li><p>Y.&nbsp;Chen, J.&nbsp;Fan, B.&nbsp;Wang, <u>Y. Yan</u> (<img class="eq" src="eqs/7227645438722938594-130.png" alt="alpha" style="vertical-align: -1px" />-<img class="eq" src="eqs/4226120147019918905-130.png" alt="beta" style="vertical-align: -4px" />), <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2021.1956501">&ldquo;Convex and Nonconvex Optimization Are Both Minimax-Optimal for Noisy Blind Deconvolution Under Random Designs,&rdquo;</a> <i>Journal of the American Statistical Association, vol. 118, no. 542, pp. 858-868, 2023</i></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><b>Statistical foundations of offline reinforcement learning</b></p>
<ul>
<li><p><u>Y. Yan</u>, G.&nbsp;Li, Y.&nbsp;Chen, J.&nbsp;Fan, <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196488">&ldquo;The Efficacy of Pessimism in Asynchronous Q-learning,&rdquo;</a> <i>IEEE Transactions on Information Theory, vol. 69, no. 11, pp. 7185-7219, 2023</i></p>
</li>
<li><p><u>Y. Yan</u>, G.&nbsp;Li, Y.&nbsp;Chen, J.&nbsp;Fan, <a href="https://pubsonline.informs.org/doi/full/10.1287/opre.2022.0342">&ldquo;Model-Based Reinforcement Learning for Offline Zero-Sum Markov Games,&rdquo;</a> accepted to <i>Operations Research</i>, 2024</p>
</li>
<li><p>G.&nbsp;Li, <u>Y. Yan</u>, Y.&nbsp;Chen, J.&nbsp;Fan, <a href="https://arxiv.org/abs/2304.07278">&ldquo;Minimax-Optimal Reward-Agnostic Exploration in Reinforcement Learning,&rdquo;</a> 2024 (accepted in part to <a href="https://proceedings.mlr.press/v247/li24a">COLT 2024</a>)</p>
</li>
</ul>

</li>
</ul>
<h2>Selected awards</h2>
<ul>
<li><p>IMS Lawrence D. Brown Award, 2024</p>
</li>
<li><p>ICCM Best Thesis Award (Silver Medal), 2024</p>
</li>
<li><p>Norbert Wiener Postdoctoral Fellowship, MIT, 2023</p>
</li>
<li><p>Charlotte Elizabeth Procter Honorific Fellowship, Princeton University, 2022</p>
</li>
<li><p>ASA Statistical Learning and Data Science Best Student Paper Award, 2022</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2024-12-02 10:45:53 EST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
